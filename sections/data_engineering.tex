\chapter{Data Engineering for LLMs}

\textit{Data engineering} is the development, implementation, and maintenance of systems and processes that take in raw data and produce high-quality, consistent information that supports downstream use cases, such as analysis and machine learning. 

There isn't more valuable asset than your data. All successful AI and ML initiatives are built on a good data engineering foundation. It's important then that we acquire, clean, and curate our data. 
% Unlike other ML models, you generally won't be starting from scratch when creating an LLM customized for your specific task. 

\section{Models and the Foundation}
The most important dataset you will need to collect when training is the model weights of a pretrained model. 

\subsection{Evaluating LLMs}
When evaluating a model, you will need two things: \Ni a \textit{metric} and \Nii a \textit{dataset}. 

\paragraph{Metrics}
\begin{itemize}
	\item ROUGE
	\item BLEU
	\item BPC: The bits per character (BPC) evaluation is an example of an entropy-based evaluation for language models. 
\end{itemize}

\paragraph{Industry benchmarks}
\begin{itemize}
	\item GLUE
	\item SuperGLUE
\end{itemize}



% \subsection{GPT}

% \begin{table}[h]
% 	\setlength{\tabcolsep}{4pt}
% 	\caption{Comparison of LLM model families}
% 	\centering
% 	\begin{tabular}{llc}
% 		\toprule
% 		Model Family & Dataset \\
% 		\midrule
% 		GPT & Common Crawl/RLHF
% 		% \cmidrule(r){1-2}
% 		% \midrule
% 		\bottomrule
% 	\end{tabular}
% \end{table}


% 	\item BLOOM
% 	\item LLaMa
% 	\item 
% \end{itemize}
% h
