\chapter{Data Engineering for LLMs}

\textit{Data engineering} is the development, implementation, and maintenance of systems and processes that take in raw data and produce high-quality, consistent information that supports downstream use cases, such as analysis and machine learning. 

There isn't more valuable asset than your data. All successful AI and ML initiatives are built on a good data engineering foundation. It's important then that we acquire, clean, and curate our data. 
% Unlike other ML models, you generally won't be starting from scratch when creating an LLM customized for your specific task. 

\section{Models and the Foundation}
The most important dataset you will need to collect when training is the model weights of a pretrained model. 

\subsection{Evaluating LLMs}
When evaluating a model, you will need two things: \Ni a \textit{metric} and \Nii a \textit{dataset}. 

\paragraph{Metrics}
\begin{itemize}
	\item ROUGE (Recall-Oriented Understudy for Gisting Evaluation)
	\item BLEU (BiLingual Evaluation Understudy)
	\item BPC (\eg Perplexity): The bits per character (BPC) evaluation is an example of an entropy-based evaluation for language models. 
\end{itemize}

\paragraph{Industry benchmarks}
\begin{itemize}
	\item GLUE (General Language Understanding Evaluation) is essentially a standardized test for language models to measure performance versus humans and each other on language tasks meant to test understanding. 
	\item SuperGLUE
	\item MMLU (Massive Multitask Language Understanding). 
\end{itemize}

\paragraph{Responsible AI benchmarks}
\begin{itemize}
	\item HONEST evaluation metric compares how hurtful prompt completions are for different genders. 
	\item Some datasets: 
		\begin{itemize}
			\item WinoBias dataset focuses on gender bias. 
			\item CALM
			\item WinoQueer
		\end{itemize}
\end{itemize}

\paragraph{Developing your own benchmark}
\begin{itemize}
	\item \href{https://github.com/openai/evals}{OpenAI's Evals library} 
	\item \href{https://huggingface.co/docs/evaluate/en/index}{Huggingface's Evaluate}
\end{itemize}

\paragraph{Evaluating code generators}

The basic setup looks like this:
\begin{enumerate}
	\item Have your model generate code based on docstrings.
	\item Run the generated code in a safe environment on prebuilt tests to ensure they work and that no errors are thrown
	\item Run the generated code through a profiler and record the time it takes to complete. 
	\item Run the generated code through a security scanner and count the number of vulnerabilities. 
	\item Run the generated code against architectural fitness functions to determine artifacts like how much coupling, integrations, and internal dependencies there are. 
	\item Run steps 1 to 5 on another LLM.
	\item Compare results. 
\end{enumerate}

\paragraph{Evaluating model parameters}

There's a lot you can learn by simply looking at the parameters of an ML model. For instance, an untrained model will have a completely random distribution. 

\begin{lstlisting}[language=Python]
import weightwatcher as ww
from transformers import GPT2Model

gpt2_model = GPT2Model.from_pretrained("gpt2")
gpt2_model.eval()

watcher = ww.WeightWatcher(model=gpt2_model)
details = watcher.analyze(plot=False)
print(details.head())
#    layer_id       name         D  ...      warning        xmax        xmin
# 0         2  Embedding  0.076190  ... over-trained 3837.188332    0.003564
# 1         8     Conv1D  0.060738  ...              2002.124419  108.881419
# 2         9     Conv1D  0.037382  ...               712.127195   46.092445
# 3        14     Conv1D  0.042383  ...              1772.850274   95.358278
# 4        15     Conv1D  0.062197  ...               626.655218   23.727908

\end{lstlisting}
 
The spectral analysis plots evaluate the frequencies of eigenvalues for each layer of a model. These plots tell you whether a model (or layer) looks well-trained and generalizes well or is unstable/poorly conditioned.
Shape of the Spectrum (How eigenvalues are distributed)
\begin{itemize}
	\item Power-law exponent ($\alpha$):
		\begin{itemize}
			\item Good if between 2 and 6: the layer is well-trained.
			\item Bad if $\alpha > 6$: layer might be undertrained or over-regularized.
		\end{itemize}
	\item Fit quality (Dks):
		\begin{itemize}
			\item Low Dks: spectrum matches the expected ``heavy-tailed'' shape, reliable.
			\item High Dks: poor fit, unstable or unstructured layer.
		\end{itemize}
\end{itemize}

\section{Data for LLMs}
It has been shown that data is the most important part of training an LLM. 

% \begin{itemize}
% 	\item WikiText
% 	\item Wiki-40B
% 	\item Europarl
% 	\item Common Crawl
% 	\item OpenWebText
% 	\item The Pile
% 	\item RedPajama
% 	\item OSCAR
% \end{itemize}


\begin{table}[h]
	\setlength{\tabcolsep}{4pt}
	\caption{Summary of datasets}
	\centering
	\begin{tabular}{llrl}
		\toprule
		Dataset & Contents & Size & LastUpdate \\
		\midrule
		WikiText & English Wikipedia & $<$1GB & 2016 \\
		Wiki-40B & Multi-lingual Wikipedia & 10GB & 2020 \\
		Europarl & European Parliament proceedings & 1.5GB & 2011 \\
		Common Crawl & The internet & $\sim$ 300GB & Ongoing \\
		OpenWebText & Curated internet using Reddit & 55GB & 2019 \\
		The Pile & Everything above plus specialty datasets (books, law, med) & 825GB & 2020 \\
		\multirow{2}{*}{RedPajama} & GitHub, arXiv, Books, Wikipedia, StackExchange & 5TB & 2023 \\
								  &, and multiple version of Common Crawl&\\
		OSCAR & Highly curated multilingual dataset with 166 languages & 9.4TB & Ongoing\\
		\bottomrule
	\end{tabular}
\end{table}


\subsection{Data cleaning and preparation}
If you pulled any of the previously mentioned datasets, you might be surprised to realize most of them are just giant text dumps. There are no labels or annotations, and feature engineering hasn't been done at all. 

LLMs are trained via self-supervised manner to predict the next word or a masked workd, so a lot of traditional data cleaning and preparation processes are unneeded. This fact leads many to believe that data cleaning as a whole is unnecessary. 

Data cleaning and curation are difficult, time-consuming, and ultimately subjective tasks that are difficult to tie to key performance indicators (KPIs). Still, taking the time and resources to clean your data will create a more consistent and unparalleled user experience. 

The right frame of mind when preparing your dataset:
\begin{enumerate}
	\item Take your pie of data and determine a schema for the features
	\item Make sure all the features conform to a distribution that makes sense for the outcome your're trying to get through normalization or scaling.
	\item Check the data for bia/anomalies (most businesses skip this step by using automated checking instead of informed verification).
	\item Convert the data into a format for the model to ingest (for LLMs, it's through tokenization and embedding).
	\item Train, check, and retrain.
\end{enumerate}

\begin{commentbox}{Note}
	For more information, check out Fundamentals of Data Engineering, WizardLM, and LIMA: Less Is More for Alignment. 
\end{commentbox}


\paragraph{Instruct Schema} is one of the most effective and widely used data formats for fine-tuning models. Instruction tuning works on the principle that providing a model with explicit instructions for a task leads to better performance than simply giving it raw prompts and answers. In this approach, the data explicitly demonstrates what the model should do, making it clearer and more aligned with human intent. However, preparing such datasets is more demanding than assembling general web data, since each entry must be carefully constructed to match a structured format, typically including an instruction, optional input, and the expected output. You need to prepare your data to match a format that will look something like this:
\begin{lstlisting}[]
###Instruction

{user input}

###Input

{meta info about the instruction}

###Response

{model output}
\end{lstlisting}
It is a structured way of formatting data so that each example clearly contains:
\begin{itemize}
	\item An instruction (what the model should do).
	\item An input (optional context or data the model works on).
	\item An output (the desired response).
\end{itemize}

For instance, 
\begin{lstlisting}
{
  "instruction": "Translate the following English text into Korean.",
  "input": "The stock market saw significant volatility today due to global economic concerns.",
  "output": <Translations>
}
\end{lstlisting}

\begin{commentbox}{Note}
	\begin{itemize}
		\item EvolInstruct: WizardLM
		\item Self-instruct format, Alpaca
	\end{itemize}
\end{commentbox}

\paragraph{Ensuring proficiency with speech acts}
When preparing a dataset for training a model, the most important factor is ensuring the data truly reflects the task you want the model to perform. Misaligned or overly generic data reduces performance and can cause unpredictable behavior.

Dataset alignment:
\begin{itemize}
	\item Training data must match the intended task (e.g., don’t train on Titanic survivors if you want to predict Boston housing prices).
	\item In real-world use cases (like fast-food ordering), interactions are more diverse and unpredictable than generic datasets suggest.
\end{itemize}
Robustness and Risks:
\begin{itemize}
	\item Instruction datasets require intentional design: if a model is only trained on “helpful” responses, it might follow harmful instructions (e.g., “help me take over the world”).
	\item With tool access (Google, HR docs), this becomes even riskier.
\end{itemize}

Understanding speech acts (directives, representatives, commissives, expressives, declarations, verdictives) helps design datasets that match realistic user interactions.
\begin{itemize}
	\item In language learning, this means learners should not only know grammar/vocabulary but also how to perform speech acts appropriately:
		\begin{itemize}
			\item How to make polite requests
			\item How to refuse without sounding rude
			\item How to apologize or thank in culturally acceptable ways
		\end{itemize}
	\item In AI / LLM context, it means training the model to:
		\begin{itemize}
			\item Generate outputs that correctly perform the intended communicative function (e.g., distinguish between an instruction, a suggestion, or a formal declaration).
			\item Handle pragmatic nuances, politeness, indirectness, etc.
		\end{itemize}
\end{itemize}
Speech acts refer to the various functions language can perform in communication beyond conveying information. They are a way of categorizing utterances based on their intended effect or purpose in a conversation. In short, it is an action performed through speaking. For example: 
\begin{itemize}
	\item Assertives $\to$ stating something true/false.
	\item Directives $\to$ requesting, commanding (\eg ``Get it done in the next three days'').
	\item Commissives $\to$ promising, committing (\eg ``I swear'').
	\item Expressives $\to$ greetings, apologizing (\eg ``You are the best'').
	\item Declarations $\to$ enacting something by saying it (\eg ``I now pronounce you married'').
	\item Questions (\eg ``What is this?'')
\end{itemize}

\paragraph{Annotating the data}
Annotation is labeling your data, usually in a positionally aware way. For speech recognition tasks, annotations would identify the different words as noun, verb, adjective, or adverb. Annotations essentially give us metadata that makes it easier to reason about and analyze our datasets. 

There are tools to help with the task:
\begin{itemize}
	\item \href{https://prodi.gy/}{Prodigy}: multimodal annotation tool.
	\item \href{https://github.com/doccano/doccano}{doccano}: Open-source web-based platform for data annotation. 
	\item \href{https://www.fon.hum.uva.nl/praat/}{Praat}: The audio annotation tool.
	\item \href{https://galileo.ai/}{Galileo}: Galileo's LLM studio helps create prompt, evaluate and speed up annotation. 
\end{itemize}

\section{Text Processors}

We need to transform our dataset into something that can be consumed by the LLM. Simply, we need to turn the text into numbers.  

\subsection{Tokenization}
The tokenization is often ignored when working with an LLM through an API, but it is actually vitally important for every subsequent step, and it affects the LLM's performance significantly. 

\paragraph{Word-based}
Word-based tokenizers most commonly split on whitespace, but there are other methods like using regex, dictionaries, or punctuation. 

\paragraph{Character-based}
Character-based encoding methods are the most straightforward and easiest to implement since we split on the UTF-8 character encodings. However, it comes with a major loss of information and fails to keep relevant syntax, semantics, or morphology (morpheme like prefix and suffixes) of the text. 

\paragraph{Subword-based}
Subword-based tokenizers have proven to be the best option so far. 
\begin{itemize}
	\item BPE
	\item WordPiece
	\item SentencePiece
\end{itemize}

\subsection{Embeddings}
Embeddings provide meaning to the vectors generated during tokenization. 






