@book{brousseau2025llms,
  title={LLMs in Production: From Language Models to Successful Products},
  author={Brousseau, C. and Sharp, M.},
  isbn={9781633437203},
  lccn={2025388475},
  url={https://books.google.co.kr/books?id=LR1BEQAAQBAJ},
  year={2025},
  publisher={Manning}
}

@misc{li2024largelanguagemodelsmanufacturing,
      title={Large Language Models for Manufacturing}, 
      author={Yiwei Li and Huaqin Zhao and Hanqi Jiang and Yi Pan and Zhengliang Liu and Zihao Wu and Peng Shu and Jie Tian and Tianze Yang and Shaochen Xu and Yanjun Lyu and Parker Blenk and Jacob Pence and Jason Rupram and Eliza Banu and Ninghao Liu and Linbing Wang and Wenzhan Song and Xiaoming Zhai and Kenan Song and Dajiang Zhu and Beiwen Li and Xianqiao Wang and Tianming Liu},
      year={2024},
      eprint={2410.21418},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.21418}, 
}
https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/

@misc{Shashank2023,
  title={Mastering LLM Techniques: Inference Optimization},
  author={Shashank Verma and Neal Vaidya},
  url={https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/},
  year={2023},
  publisher={Online}
}

@online{Aleksa2023,
  title={ELI5: FlashAttention},
  author={Aleksa Gordic},
  url={https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad},
  year={2023},
  urldate      = {2025-10-11},   % date you accessed it (YYYY-MM-DD)
}

@online{Anshul2024,
  author       = {Anshul Rana},
  title        = {DRAM vs SDRAM vs SRAM vs VRAM: Understanding Different Memory Types},
  year         = {2024},
  url          = {https://storedbits.com/dram-vs-sdram-vs-sram-vs-vram/},
  urldate      = {2025-10-11},   % date you accessed it (YYYY-MM-DD)
  % organization = {Org/Project Name},  % optional
  % version      = {v1.2.3},            % optional (software/docs)
  note         = {Optional extra info} % optional
}

@online{Horace2022,
  author={Horace He},
  title={Making Deep Learning Go Brrrr From First Principles},
  year={2022},
  url          = {https://horace.io/brrr_intro.html},
  urldate      = {2025-10-11},   % date you accessed it (YYYY-MM-DD)
  % organization = {Org/Project Name},  % optional
  % version      = {v1.2.3},            % optional (software/docs)
  note         = {Optional extra info} % optional
}

@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@article{Xubin2025,
author = {Wang, Xubin and Tang, Zhiqing and Guo, Jianxiong and Meng, Tianhui and Wang, Chenhao and Wang, Tian and Jia, Weijia},
title = {Empowering Edge Intelligence: A Comprehensive Survey on On-Device AI Models},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3724420},
doi = {10.1145/3724420},
abstract = {The rapid advancement of artificial intelligence (AI) technologies has led to an increasing deployment of AI models on edge and terminal devices, driven by the proliferation of the Internet of Things (IoT) and the need for real-time data processing. This survey comprehensively explores the current state, technical challenges, and future trends of on-device AI models. We define on-device AI models as those designed to perform local data processing and inference, emphasizing their characteristics such as real-time performance, resource constraints, and enhanced data privacy. The survey is structured around key themes, including the fundamental concepts of AI models, application scenarios across various domains, and technical challenges faced in edge environments. We also discuss optimization and implementation strategies, such as data preprocessing, model compression, and hardware acceleration, which are essential for effective deployment. Furthermore, we examine the impact of emerging technologies, including edge computing and foundation models, on the evolution of on-device AI models. By providing a structured overview of the challenges, solutions, and future directions, this survey aims to facilitate further research and application of on-device AI, ultimately contributing to the advancement of intelligent systems in everyday life.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {228},
numpages = {39},
keywords = {On-device AI, edge intelligence, real-time processing, model optimization, data privacy, survey}
}
